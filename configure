#!/bin/bash

## Set up python-related environment settings
PYTHON_BIN_PATH=$(which python)
# No Google Cloud Platform support
TF_NEED_GCP=0

## Find swig path
if [ -z "$SWIG_PATH" ]; then
  SWIG_PATH=`type -p swig 2> /dev/null`
fi
if [[ ! -e "$SWIG_PATH" ]]; then
  echo "Can't find swig.  Ensure swig is in \$PATH or set \$SWIG_PATH."
  exit 1
fi
echo "$SWIG_PATH" > tensorflow/tools/swig/swig_path

# Invoke python_config and set up symlinks to python includes
(./util/python/python_config.sh --setup "$PYTHON_BIN_PATH";) || exit -1

## Set up Cuda-related environment settings

TF_NEED_CUDA=1
GCC_HOST_COMPILER_PATH=$(which gcc)

# Find out where the CUDA toolkit is installed
OSNAME=`uname -s`
TF_CUDA_VERSION=""
TF_CUDA_EXT=""
CUDA_RT_LIB_PATH="lib64/libcudart.so${TF_CUDA_EXT}"
CUDA_TOOLKIT_PATH=/usr/local/cuda
TF_CUDNN_VERSION=""
CUDNN_INSTALL_PATH=${CUDA_TOOLKIT_PATH}

cat > third_party/gpus/cuda/cuda.config <<EOF
# CUDA_TOOLKIT_PATH refers to the CUDA toolkit.
CUDA_TOOLKIT_PATH="$CUDA_TOOLKIT_PATH"

# CUDNN_INSTALL_PATH refers to the cuDNN toolkit. The cuDNN header and library
# files can be either in this directory, or under include/ and lib64/
# directories separately.
CUDNN_INSTALL_PATH="$CUDNN_INSTALL_PATH"

# The Cuda SDK version that should be used in this build (empty to use libcudart.so symlink)
TF_CUDA_VERSION=$TF_CUDA_VERSION

# The Cudnn version that should be used in this build (empty to use libcudnn.so symlink)
TF_CUDNN_VERSION=$TF_CUDNN_VERSION
EOF

# Configure the gcc host compiler to use
export WARNING=$DO_NOT_SUBMIT_WARNING
perl -pi -e "s,CPU_COMPILER = \('.*'\),# \$ENV{WARNING}\nCPU_COMPILER = ('$GCC_HOST_COMPILER_PATH'),s" third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc
perl -pi -e "s,GCC_HOST_COMPILER_PATH = \('.*'\),# \$ENV{WARNING}\nGCC_HOST_COMPILER_PATH = ('$GCC_HOST_COMPILER_PATH'),s" third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc

# Configure the platform name.
perl -pi -e "s,PLATFORM = \".*\",PLATFORM = \"$OSNAME\",s" third_party/gpus/cuda/platform.bzl

# Configure the Cuda toolkit version to work with.
perl -pi -e "s,(GetCudaVersion.*return )\"[0-9\.]*\",\1\"$TF_CUDA_VERSION\",s" tensorflow/stream_executor/dso_loader.cc
perl -pi -e "s,CUDA_VERSION = \"[0-9\.]*\",CUDA_VERSION = \"$TF_CUDA_VERSION\",s" third_party/gpus/cuda/platform.bzl

# Configure the Cudnn version to work with.
perl -pi -e "s,(GetCudnnVersion.*return )\"[0-9\.]*\",\1\"$TF_CUDNN_VERSION\",s" tensorflow/stream_executor/dso_loader.cc
perl -pi -e "s,CUDNN_VERSION = \"[0-9\.]*\",CUDNN_VERSION = \"$TF_CUDNN_VERSION\",s" third_party/gpus/cuda/platform.bzl


# Configure the compute capabilities that TensorFlow builds for.
# Since Cuda toolkit is not backward-compatible, this is not guaranteed to work.
# 3.0=k520
# 3.7=k80
# https://developer.nvidia.com/cuda-gpus
TF_CUDA_COMPUTE_CAPABILITIES=3.0,3.7

if [ ! -z "$TF_CUDA_COMPUTE_CAPABILITIES" ]; then
  export WARNING="Unofficial setting. DO NOT"" SUBMIT!!!"
  function CudaGenCodeOpts() {
    OUTPUT=""
    for CAPABILITY in $@; do
      OUTPUT=${OUTPUT}"   \"${CAPABILITY}\",     "
    done
    echo $OUTPUT
  }
  export CUDA_GEN_CODES_OPTS=$(CudaGenCodeOpts ${TF_CUDA_COMPUTE_CAPABILITIES//,/ })
  perl -pi -0 -e 's,\n( *)([^\n]*supported_cuda_compute_capabilities\s*=\s*\[).*?(\]),\n\1# $ENV{WARNING}\n\1\2$ENV{CUDA_GEN_CODES_OPTS}\3,s' third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc
  function CudaVersionOpts() {
    OUTPUT=""
    for CAPABILITY in $@; do
      OUTPUT=$OUTPUT"CudaVersion(\"${CAPABILITY}\"), "
    done
    echo $OUTPUT
  }
  export CUDA_VERSION_OPTS=$(CudaVersionOpts ${TF_CUDA_COMPUTE_CAPABILITIES//,/ })
  perl -pi -0 -e 's,\n( *)([^\n]*supported_cuda_compute_capabilities\s*=\s*\{).*?(\}),\n\1// $ENV{WARNING}\n\1\2$ENV{CUDA_VERSION_OPTS}\3,s' tensorflow/core/common_runtime/gpu/gpu_device.cc
fi

# Invoke the cuda_config.sh and set up the TensorFlow's canonical view of the Cuda libraries
(cd third_party/gpus/cuda; ./cuda_config.sh;) || exit -1

echo "Configuration finished"
